{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e250e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    USE_WANDB = True\n",
    "except ImportError:\n",
    "    USE_WANDB = False\n",
    "    print(\"wandb not installed, skipping wandb logging\")\n",
    "from dataloader import get_train_datasets\n",
    "from widemlp import MLP, inverse_document_frequency, prepare_inputs_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad122a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "MODEL_NAME = \"\"\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 4\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "TRAIN_LOGGING_STEPS = 1\n",
    "EVAL_LOGGING_STEPS = 100\n",
    "THRESHOLD = 0.5\n",
    "DATASET_SIZE = 15_000\n",
    "LOG_WANDB = True\n",
    "PATH = \"widemlp-4cls.pt\"\n",
    "TEST_SPLIT = 0.2\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cuda devices\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA devices:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_WANDB:\n",
    "    wandb.init(project=\"ood-widemlp\")\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"seed\": SEED,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "            \"train_logging_steps\": TRAIN_LOGGING_STEPS,\n",
    "            \"eval_logging_steps\": EVAL_LOGGING_STEPS,\n",
    "            \"threshold\": THRESHOLD,\n",
    "            \"test_split\": TEST_SPLIT,\n",
    "            \"num_hidden_layers\": NUM_HIDDEN_LAYERS,\n",
    "            \"num_classes\": NUM_CLASSES,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def load_data(path: str, eval_size: int = 0.2) -> Dataset:\n",
    "    df = pd.read_json(path) if path.endswith(\".json\") else pd.read_csv(path)\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset.shuffle(seed=42)\n",
    "    split_dataset = dataset.train_test_split(test_size=eval_size)\n",
    "    return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83e6d2",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4644cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_train_datasets(dataset_size=DATASET_SIZE, seed=SEED, split=TEST_SPLIT)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data[\"train\"], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    data[\"test\"], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1f4cb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9acbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    tokenizer.encode(raw_doc, padding=False, truncation=True, max_length=None)\n",
    "    for raw_doc in data[\"train\"][\"text\"]\n",
    "]\n",
    "idf = inverse_document_frequency(docs, len(tokenizer))\n",
    "model = MLP(\n",
    "    vocab_size=len(tokenizer),\n",
    "    num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    idf=idf,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.idf = model.idf.to(DEVICE) if model.idf is not None else None\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model: torch.nn.Module,\n",
    "    valid_loader: torch.utils.data.DataLoader,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    threshold: float,\n",
    ") -> dict:\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    validation_losses = []\n",
    "    max_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            inputs = tokenizer(\n",
    "                batch[\"text\"],\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=False,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(DEVICE)\n",
    "            flat_inputs, offsets = prepare_inputs_optimized(inputs[\"input_ids\"], device=DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE, dtype=torch.long)\n",
    "            one_hot_targets = torch.nn.functional.one_hot(\n",
    "                labels, num_classes=NUM_CLASSES\n",
    "            ).to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "            loss, logits = model(flat_inputs, offsets, one_hot_targets)\n",
    "            validation_losses.append(loss.item())\n",
    "            probabilities = torch.sigmoid(logits)  # -> 0-1\n",
    "            batch_predictions = []\n",
    "            for i in range(probabilities.size(0)):\n",
    "                sample_probabilities = probabilities[i]\n",
    "                max_probs.append(sample_probabilities.max().item())\n",
    "                thresholded_labels_indices = torch.where(\n",
    "                    sample_probabilities > threshold\n",
    "                )[0]\n",
    "                if len(thresholded_labels_indices) > 1:\n",
    "                    best_label_index = thresholded_labels_indices[\n",
    "                        torch.argmax(sample_probabilities[thresholded_labels_indices])\n",
    "                    ]\n",
    "                    prediction_vector = torch.zeros(NUM_CLASSES, dtype=torch.int)\n",
    "                    prediction_vector[best_label_index] = 1\n",
    "                    batch_predictions.append(prediction_vector.cpu().numpy())\n",
    "                else:\n",
    "                    predictions = (sample_probabilities > threshold).int()\n",
    "                    batch_predictions.append(predictions.cpu().numpy())\n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_labels.extend(one_hot_targets.cpu().numpy())\n",
    "\n",
    "    avg_validation_loss = np.mean(validation_losses)\n",
    "\n",
    "    # Convert to numpy arrays for metric calculation\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "    all_labels_np = np.array(all_labels)\n",
    "\n",
    "    # Calculate metrics\n",
    "    macro_f1 = f1_score(\n",
    "        all_labels_np, all_predictions_np, average=\"macro\", zero_division=0\n",
    "    )  # zero_division=0 to handle cases with no predicted labels\n",
    "    micro_f1 = f1_score(\n",
    "        all_labels_np, all_predictions_np, average=\"micro\", zero_division=0\n",
    "    )\n",
    "    macro_precision = precision_score(\n",
    "        all_labels_np, all_predictions_np, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    macro_recall = recall_score(\n",
    "        all_labels_np, all_predictions_np, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    micro_precision = precision_score(\n",
    "        all_labels_np, all_predictions_np, average=\"micro\", zero_division=0\n",
    "    )\n",
    "    micro_recall = recall_score(\n",
    "        all_labels_np, all_predictions_np, average=\"micro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    scores = {\n",
    "        \"validation_loss\": avg_validation_loss,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_precision,\n",
    "        \"macro_recall\": macro_recall,\n",
    "        \"micro_precision\": micro_precision,\n",
    "        \"micro_recall\": micro_recall,\n",
    "        \"max_probs\": np.mean(max_probs),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c835176",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "for _epoch in range(EPOCHS):\n",
    "    step = 0\n",
    "    batch_train_loss = []\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        model.train()\n",
    "        inputs = tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=False,\n",
    "        )\n",
    "        flat_inputs, offsets = prepare_inputs_optimized(inputs[\"input_ids\"], device=DEVICE)\n",
    "        labels = batch[\"label\"].to(DEVICE, dtype=torch.long)\n",
    "        one_hot_targets = torch.nn.functional.one_hot(\n",
    "            labels, num_classes=NUM_CLASSES\n",
    "        ).to(DEVICE, dtype=torch.float32)\n",
    "        # inputs[\"label\"] = one_hot_targets\n",
    "        loss, logits = model(flat_inputs, offsets, one_hot_targets)\n",
    "        loss.backward()\n",
    "        step += 1  # noqa: SIM113\n",
    "        batch_train_loss.append(loss.item())\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if step % TRAIN_LOGGING_STEPS == 0:\n",
    "            accuracy = np.mean(batch_train_loss)\n",
    "            if LOG_WANDB:\n",
    "                wandb.log({\"train_loss\": float(accuracy), \"epoch\" : _epoch})\n",
    "            else:\n",
    "                print(f\"Step {step}, Train Loss: {accuracy:.4f}\")\n",
    "        if step % EVAL_LOGGING_STEPS == 0:\n",
    "            scores = evaluate(model, valid_loader, tokenizer, threshold=THRESHOLD)\n",
    "            if LOG_WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"validation_loss\": float(scores[\"validation_loss\"]),\n",
    "                        \"test/macro_f1\": float(scores[\"macro_f1\"]),\n",
    "                        \"test/micro_f1\": float(scores[\"micro_f1\"]),\n",
    "                        \"test/macro_recall\": float(scores[\"macro_recall\"]),\n",
    "                        \"test/micro_recall\": float(scores[\"micro_recall\"]),\n",
    "                        \"test/macro_precision\": float(scores[\"macro_precision\"]),\n",
    "                        \"test/micro_precision\": float(scores[\"micro_precision\"]),\n",
    "                        \"test/max_probs\": float(scores[\"max_probs\"]),\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Step {step}, Validation Loss: {scores['validation_loss']:.4f}, Macro F1: {scores['macro_f1']:.4f}, Micro F1: {scores['micro_f1']:.4f}\"\n",
    "                )\n",
    "if LOG_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102bb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    PATH\n",
    ")\n",
    "torch.save(idf, f\"{PATH.replace(\".pt\", \"_idf.pt\")}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
