{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from dataloader import get_eval_datasets\n",
    "from widemlp import MLP, prepare_inputs_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24582140",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "BATCH_SIZE = 64\n",
    "SEED = 42\n",
    "MODEL_NAME = \"\"\n",
    "EPOCHS = 1\n",
    "NUM_CLASSES = 3\n",
    "THRESHOLD = 0.5\n",
    "DATASET_SIZE = 15_000\n",
    "TEST_SPLIT = 0.2\n",
    "NUM_HIDDEN_LAYERS = 3\n",
    "NUM_CLASSES = 3\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09048473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = get_eval_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ef20f",
   "metadata": {},
   "source": [
    "# MLP 3cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa13e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path :str, idf_path : str, num_classes : int, num_hidden_layers : int) -> MLP:\n",
    "    idf = torch.load(idf_path).to(DEVICE)\n",
    "    checkpoint = torch.load(\n",
    "        model_path, weights_only=True, map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    # print checkpoint keys\n",
    "    wide_mlp = MLP(\n",
    "        vocab_size=len(tokenizer),\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "        num_classes=num_classes,\n",
    "        idf=idf,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "    )\n",
    "    wide_mlp.to(DEVICE)\n",
    "    wide_mlp.idf = idf if wide_mlp.idf is not None else None\n",
    "    wide_mlp.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    wide_mlp.eval()\n",
    "    print(f\"Successfully loaded PyTorch model on {DEVICE}\")\n",
    "    return wide_mlp\n",
    "\n",
    "def inference(\n",
    "    model: torch.nn.Module,\n",
    "    text: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    threshold: float,\n",
    ") -> dict:\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "        \n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(DEVICE)\n",
    "    flat_inputs, offsets = prepare_inputs_optimized(inputs[\"input_ids\"], device=DEVICE)\n",
    "\n",
    "    logits = model(flat_inputs, offsets)\n",
    "    probabilities = torch.sigmoid(logits)  # -> 0-1\n",
    "    batch_predictions = []\n",
    "    for i in range(probabilities.size(0)):\n",
    "        sample_probabilities = probabilities[i]\n",
    "        thresholded_labels_indices = torch.where(\n",
    "            sample_probabilities > threshold\n",
    "        )[0]\n",
    "        if len(thresholded_labels_indices) >= 1:\n",
    "            best_label_index = thresholded_labels_indices[\n",
    "                torch.argmax(sample_probabilities[thresholded_labels_indices])\n",
    "            ]\n",
    "            prediction_vector = torch.zeros(NUM_CLASSES, dtype=torch.int)\n",
    "            prediction_vector[best_label_index] = 1\n",
    "            batch_predictions.append(prediction_vector.cpu().numpy())\n",
    "        else:\n",
    "            # predictions = (sample_probabilities > threshold).int()\n",
    "            batch_predictions.append(np.array([0,0,0]))\n",
    "    all_predictions.extend(batch_predictions)\n",
    "\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "    return all_predictions_np\n",
    "\n",
    "models = [\n",
    "    (\"widemlp-23-30.pt\",3, \"widemlp-3cls-v3_idf.pt\"),\n",
    "    (\"widemlp-3cls-v3.pt\", 10, \"widemlp-3cls-v3_idf.pt\"),\n",
    "# (\"widemlp-3cls-v2.pt\",3, \"widemlp-3cls-v2_idf.pt\"),\n",
    "# (\"widemlp-3cls-v3-3l.pt\",3, \"widemlp-3cls-v3-3l_idf.pt\"),\n",
    "# (\"widemlp-3cls-v3-64l.pt\",64, \"widemlp-3cls-v3-64l_idf.pt\"),\n",
    "# (\"widemlp-3cls-v3-128l.pt\",128, \"widemlp-3cls-v3-128l_idf.pt\")\n",
    "]\n",
    "\n",
    "# Model: widemlp-23-30.pt - 3, Mean : 92.26000000000002, Scores: [92.30000000000001, 92.30000000000001, 92.25555555555556, 92.23333333333333, 92.21111111111111], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3.pt - 10, Mean : 85.6, Scores: [85.6, 85.6, 85.6, 85.6, 85.6], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v2.pt - 3, Mean : 34.63777777777778, Scores: [36.72222222222222, 35.82222222222222, 34.044444444444444, 33.41111111111111, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-3l.pt - 3, Mean : 71.39333333333335, Scores: [71.54444444444444, 71.52222222222223, 71.43333333333334, 71.33333333333334, 71.13333333333334], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-64l.pt - 64, Mean : 33.18888888888889, Scores: [33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-128l.pt - 128, Mean : 33.18888888888889, Scores: [33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "for model_name, num_hidden_layers, idf_path in models:\n",
    "    model_scores = []\n",
    "    wide_mlp = load_model(\n",
    "        model_path=model_name,\n",
    "        idf_path=idf_path,\n",
    "        num_classes=3,\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "    )\n",
    "    for threshold in tqdm([0.5, 0.75, 0.9, 0.99]):\n",
    "        data = []\n",
    "        ood = pd.read_csv(\"data/ood_eval.csv\")\n",
    "        for i in ood['prompt'].values:\n",
    "            results = inference(wide_mlp,i, tokenizer, threshold)\n",
    "            data.append(results[0])\n",
    "        ood['pred'] = data\n",
    "        ood['pred'] = ood['pred'].apply(lambda x: np.argmax(x))\n",
    "        ood.to_csv(f\"data/mlp/ood_eval_{model_name}_threshold_{threshold}.csv\", index=False)\n",
    "        data = []\n",
    "        domain = pd.read_csv(\"data/domain_eval.csv\")\n",
    "        for i in domain['text'].values:\n",
    "            results = inference(wide_mlp,i, tokenizer, threshold)\n",
    "            data.append(results[0])\n",
    "        domain['pred'] = data\n",
    "        domain['pred'] = domain['pred'].apply(lambda x: np.argmax(x))\n",
    "        domain.to_csv(f\"data/mlp/domain_eval_{model_name}_threshold_{threshold}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
